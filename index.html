<!DOCTYPE html>
<html lang="es">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>UNACH Chatbot - Proyecto</title>
        <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;600&display=swap" rel="stylesheet">
        <style>
            /* Estilos generales */
            body {
                font-family: 'Poppins', sans-serif;
                margin: 0;
                padding: 0;
                background-color: #e9eef5;
                line-height: 1.6;
                color: #333;
            }
    
            /* Banner */
            .banner {
                background: linear-gradient(to right, #1a73e8, #4caf50);
                color: white;
                padding: 80px 0;
                text-align: center;
            }
    
            .banner h1 {
                font-size: 3.5em;
                margin: 0;
                letter-spacing: 2px;
                text-shadow: 2px 2px 5px rgba(0, 0, 0, 0.3);
            }
    
            .banner p {
                font-size: 1.5em;
                margin-top: 10px;
            }
    
            /* Contenedor general */
            .container {
                width: 90%;
                max-width: 1200px;
                margin: 30px auto;
                background-color: white;
                padding: 20px;
                border-radius: 8px;
                box-shadow: 0px 4px 12px rgba(0, 0, 0, 0.1);
            }
    
            h2 {
                font-size: 2em;
                margin-bottom: 15px;
                color: #1a73e8;
            }
    
            p {
                font-size: 1.1em;
                color: #555;
                margin-bottom: 20px;
            }
    
            ul {
                list-style-type: disc;
                margin-left: 20px;
            }
    
            li {
                margin-bottom: 10px;
            }
    
            pre {
                background-color: #2d2d2d;
                color: #f8f8f2;
                padding: 15px;
                border-radius: 5px;
                text-align: left;
                margin: 20px auto;
                max-width: 90%;
                overflow: auto;
            }
    
            code {
                font-family: "Courier New", Courier, monospace;
                font-size: 0.9em;
            }
    
            /* Secci贸n de resultados centrada */
            .results-section {
                margin: 40px 0;
            }
    
            .results-section h3 {
                font-size: 1.5em;
                color: #333;
            }
    
            .results-section img {
                max-width: 800px;
                width: 100%;
                height: auto;
                border-radius: 8px;
                box-shadow: 0px 4px 12px rgba(0, 0, 0, 0.1);
            }
    
            /* Estilos del footer */
            footer {
                text-align: center;
                padding: 20px;
                background-color: #333;
                color: white;
                margin-top: 40px;
            }
    
            /* Botones */
            .btn {
                display: inline-block;
                background-color: #4caf50;
                color: white;
                padding: 10px 20px;
                border-radius: 5px;
                text-decoration: none;
                font-size: 1.1em;
            }
    
            .btn:hover {
                background-color: #45a049;
            }
    
        </style>
</head>

<body>

    <!-- Banner superior -->
    <div class="banner">
        <h1>UNACH Chatbot</h1>
        <p>Proyecto de Inteligencia Artificial - NLP</p>
    </div>

    <!-- Contenedor del contenido principal -->
    <div class="container">
        <!-- Objetivo del proyecto -->
        <h2>Objetivo del Proyecto</h2>
        <p>
            El objetivo principal de este proyecto es desarrollar un chatbot inteligente para la Universidad Nacional de Chimborazo 
            (UNACH), que utilice procesamiento de lenguaje natural (NLP) para asistir a estudiantes y personal administrativo. 
            El chatbot est谩 dise帽ado para responder preguntas sobre procesos de titulaci贸n, requisitos, fechas importantes y otros temas relevantes.
        </p>

        <!-- Pasos realizados -->
        <h2>Pasos Realizados</h2>
        <ul>
            <li>An谩lisis del problema y definici贸n de los requisitos del chatbot.</li>
            <li>Recopilaci贸n de datos: Preguntas frecuentes de estudiantes y administrativos.</li>
            <li>Entrenamiento de un modelo basado en RoBERTa para la clasificaci贸n de intenciones.</li>
            <li>Desarrollo de la interfaz del chatbot utilizando la biblioteca Streamlit.</li>
            <li>Implementaci贸n de un modelo de clasificaci贸n de secuencias para predecir las intenciones de los usuarios.</li>
        </ul>

        <!-- Conocimientos previos -->
        <h2>Conocimientos Previos Utilizados</h2>
        <p>
            Para llevar a cabo este proyecto, se requiri贸 el dominio de las siguientes 谩reas:
        </p>
        <ul>
            <li><strong>Procesamiento de Lenguaje Natural (NLP)</strong>: Uso de modelos como RoBERTa y t茅cnicas de preprocesamiento de texto.</li>
            <li><strong>Machine Learning y Deep Learning</strong>: Entrenamiento de modelos de clasificaci贸n y ajuste de hiperpar谩metros.</li>
            <li><strong>Python y Bibliotecas de IA</strong>: Uso de bibliotecas como PyTorch, PyTorch Lightning y Hugging Face Transformers.</li>
            <li><strong>Streamlit</strong>: Desarrollo de una interfaz interactiva para el chatbot.</li>
        </ul>

        <!-- Aumento de Datos con NLP Augmentation -->
        <h2>Aumento de Datos con NLP Augmentation</h2>
        <p>
            Para mejorar la calidad y robustez del modelo, se utiliz贸 la t茅cnica de <strong>Aumento de Datos</strong>. Esta t茅cnica nos permiti贸 generar m谩s ejemplos de patrones de texto mediante la sustituci贸n de palabras por sin贸nimos, lo que ayuda a que el modelo generalice mejor. Utilizamos la biblioteca <strong>nlpaug</strong> con un <em>augmentador de sin贸nimos</em>, lo que permiti贸 agregar m煤ltiples variantes para cada patr贸n original.
        </p>
        <p>
            El objetivo es ampliar el conjunto de datos sin perder coherencia en las frases generadas. Adem谩s, aplicamos un filtro para asegurarnos de que las nuevas frases sean coherentes y no repetitivas.
        </p>

        <!-- C贸digo de Aumento de Datos -->
        <h2>C贸digo de Aumento de Datos</h2>
        <pre>
<code>
import json 
import nlpaug.augmenter.word as naw

# Cargar el dataset JSON original
with open('/home/emontenegrob/Labs_NLP/prueba2_chatbot/intents_universidad2.json', 'r') as file:
    data = json.load(file)

# Inicializar el augmentador de sin贸nimos con una probabilidad menor y m谩s restricciones
aug = naw.SynonymAug(aug_src='wordnet', aug_min=1, aug_max=1, aug_p=0.1)

# Definir cu谩ntos ejemplos adicionales quieres generar por cada patr贸n original
num_augmented_examples = 3

def es_coherente(texto):
    """Funci贸n simple para evitar palabras incorrectas o incoherentes"""
    palabras_incoherentes = ["pine tree state", "atomic", "mile", "number"]
    return all(palabra not in texto.lower() for palabra in palabras_incoherentes)

# Aumentar los patrones de entrada controlando la coherencia
for intent in data['intents']:
    original_patterns = intent['patterns'][:]
    for pattern in original_patterns:
        for _ in range(num_augmented_examples):
            augmented_pattern = aug.augment(pattern)
            if isinstance(augmented_pattern, list):
                augmented_pattern = augmented_pattern[0]
            if es_coherente(augmented_pattern) and augmented_pattern != pattern:
                intent['patterns'].append(augmented_pattern)

# Guardar el dataset aumentado
with open('/home/emontenegrob/Labs_NLP/prueba2_chatbot/intents_universidad2_augmented_clean.json', 'w') as file:
    json.dump(data, file, indent=4, ensure_ascii=False)

print("Dataset aumentado y filtrado guardado en 'intents_universidad2_augmented.json'.")
</code>
        </pre>

        <!-- Descripci贸n del modelo -->
        <h2>Modelo Utilizado: RoBERTa</h2>
        <p>
            En este proyecto, se utiliza el modelo <strong>RoBERTa</strong> (Robustly optimized BERT approach), una variante optimizada de BERT, que mejora el rendimiento al eliminar algunas limitaciones del modelo original. Este modelo es ideal para tareas de clasificaci贸n de texto y fue entrenado para clasificar intenciones en el chatbot.
        </p>

        <!-- Arquitectura de RoBERTa -->
        <h2>Arquitectura de RoBERTa</h2>
        <p>
            RoBERTa es una arquitectura de red neuronal basada en transformadores, que es capaz de comprender el contexto en una secuencia de texto. Utiliza un proceso de preentrenamiento similar a BERT, basado en el modelo de enmascaramiento de palabras. RoBERTa ha sido optimizado para mejorar el rendimiento en tareas de procesamiento de lenguaje natural al utilizar:
        </p>
        <ul>
            <li>M谩s datos de entrenamiento.</li>
            <li>Mayor tama帽o de mini-batch y secuencias m谩s largas.</li>
            <li>Eliminaci贸n de la predicci贸n de la siguiente oraci贸n para mejorar la comprensi贸n contextual.</li>
        </ul>

        <!-- Hiperpar谩metros usados -->
        <h2>Hiperpar谩metros Utilizados</h2>
        <ul>
            <li><strong>Tasa de aprendizaje (learning rate)</strong>: 5e-5</li>
            <li><strong>Optimizaci贸n</strong>: Usamos el optimizador AdamW, con decaimiento de peso (`weight_decay`) de 0.01.</li>
            <li><strong>Programaci贸n de la tasa de aprendizaje</strong>: Cosine Annealing con un T_max de 10.</li>
            <li><strong>Early Stopping</strong>: Implementado con paciencia de 3 茅pocas sin mejora en la validaci贸n.</li>
            <li><strong>Batch Size</strong>: 32</li>
        </ul>

        <!-- C贸digo del modelo -->
        <h2>C贸digo del Modelo: train_model.py</h2>
        <pre>
<code>
import json
import torch
import pytorch_lightning as pl
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from transformers import RobertaTokenizer, RobertaForSequenceClassification, AdamW
from torch.utils.data import DataLoader, TensorDataset
from torch.optim.lr_scheduler import CosineAnnealingLR
from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint

# Definir el path donde est谩n los archivos guardados
path = '/home/emontenegrob/Labs_NLP/prueba2_chatbot/'

class RobertaClassifier(pl.LightningModule):
    def __init__(self, num_labels, learning_rate=5e-5, weight_decay=0.01):
        super(RobertaClassifier, self).__init__()
        self.save_hyperparameters()
        self.model = RobertaForSequenceClassification.from_pretrained(
            'roberta-base', num_labels=num_labels, hidden_dropout_prob=0.4)
        self.learning_rate = learning_rate
        self.weight_decay = weight_decay

    def forward(self, input_ids, attention_mask, labels=None):
        return self.model(input_ids, attention_mask=attention_mask, labels=labels)

    def training_step(self, batch, batch_idx):
        input_ids, attention_mask, labels = batch
        outputs = self(input_ids, attention_mask, labels)
        loss = outputs.loss
        self.log('train_loss', loss)
        return loss

    def validation_step(self, batch, batch_idx):
        input_ids, attention_mask, labels = batch
        outputs = self(input_ids, attention_mask, labels)
        val_loss = outputs.loss
        preds = torch.argmax(outputs.logits, dim=-1)
        acc = (preds == labels).float().mean()
        self.log('val_loss', val_loss, prog_bar=True)
        self.log('val_acc', acc, prog_bar=True)
        return val_loss

    def configure_optimizers(self):
        optimizer = AdamW(self.parameters(), lr=self.learning_rate, weight_decay=self.weight_decay)
        scheduler = CosineAnnealingLR(optimizer, T_max=10)
        return [optimizer], [scheduler]

# Entrenamiento
trainer = pl.Trainer(max_epochs=30, accelerator='gpu', devices=1)
trainer.fit(model)
</code>
        </pre>

         <!-- Objetivo del proyecto -->
         <h2>Resultados del Entrenamiento del Modelo</h2>
         <p>
             Los resultados obtenidos despu茅s de entrenar el modelo de clasificaci贸n basado en RoBERTa muestran un desempe帽o excelente en el conjunto de validaci贸n. A continuaci贸n, se detallan los principales resultados:
         </p>
 
         <ul>
             <li><strong>Precisi贸n de validaci贸n (val_acc)</strong>: <strong>94.9%</strong> de precisi贸n en las predicciones del modelo sobre el conjunto de validaci贸n.</li>
             <li><strong>P茅rdida de validaci贸n (val_loss)</strong>: La p茅rdida de validaci贸n fue de <strong>0.201</strong>, lo que indica que el modelo tiene un buen ajuste con un bajo error en las predicciones.</li>
         </ul>
 
         <p>
             Estos resultados sugieren que el modelo ha aprendido bien las caracter铆sticas de los datos y es capaz de generalizar correctamente. 
         </p>
 
         <!-- Imagen de los resultados -->
         <div class="results-image">
             <h3>Captura de los resultados</h3>
             <img src="imagenes\train.png" alt="Resultados del entrenamiento">
         </div>
        <!-- Descripci贸n del modelo de interacci贸n -->
        <h2>Interacci贸n con el Modelo</h2>
        <p>
            Para interactuar con el modelo preentrenado de RoBERTa, se utiliza una interfaz de consola simple que permite a los usuarios
            escribir preguntas y obtener respuestas inmediatas del chatbot. El modelo predice la intenci贸n de la pregunta del usuario y selecciona
            una respuesta basada en las respuestas definidas para esa intenci贸n.
        </p>

        <!-- Predicci贸n de la intenci贸n -->
        <h2>Predicci贸n de la Intenci贸n</h2>
        <p>
            El proceso de predicci贸n comienza con la tokenizaci贸n de la entrada del usuario. Esta entrada es transformada en tokens utilizando el
            tokenizador de RoBERTa, y luego se pasa al modelo preentrenado. El modelo genera logits, y el logit m谩s alto se convierte en la clase (o intenci贸n) predicha.
        </p>

        <ul>
            <li>La entrada del usuario se convierte en tokens utilizando el tokenizador preentrenado de RoBERTa.</li>
            <li>El modelo predice la clase con la mayor probabilidad utilizando <strong>torch.argmax()</strong>.</li>
            <li>Se mapea la clase predicha a una etiqueta de intenci贸n predefinida.</li>
        </ul>

        <!-- Selecci贸n de Respuestas -->
        <h2>Selecci贸n de Respuestas</h2>
        <p>
            Una vez que se ha predicho la intenci贸n del usuario, el chatbot selecciona una respuesta adecuada de la lista de respuestas predefinidas.
            Para hacer la interacci贸n m谩s din谩mica y natural, se selecciona una respuesta aleatoria utilizando la funci贸n <strong>random.choice()</strong>.
        </p>

        <!-- C贸digo del archivo model_lightning.py -->
        <h2>C贸digo del Archivo: model_lightning.py</h2>
        <pre>
<code>
import torch
from transformers import RobertaTokenizer, RobertaForSequenceClassification
import json
import random

# Definir el path donde est谩n los archivos guardados
path = '/home/emontenegrob/Labs_NLP/prueba2_chatbot/roberta_complete_model/'

# Cargar el tokenizador y el modelo guardado
tokenizer = RobertaTokenizer.from_pretrained(path)
model = RobertaForSequenceClassification.from_pretrained(path)

# Mover el modelo a la GPU si est谩 disponible
device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
model.to(device)
model.eval()  # Establecer el modo de evaluaci贸n

# Cargar las etiquetas del dataset original (las intenciones)
with open('/home/emontenegrob/Labs_NLP/prueba2_chatbot/intents_universidad2.json', 'r') as file:
    data = json.load(file)

# Obtener el mapeo de etiquetas (intenciones)
labels = [intent['tag'] for intent in data['intents']]

# Funci贸n para predecir la intenci贸n del usuario
def predict_intent(text):
    inputs = tokenizer(text, padding=True, truncation=True, return_tensors="pt", max_length=64)
    inputs = {key: value.to(device) for key, value in inputs.items()}
    
    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits
        predicted_class_id = torch.argmax(logits, dim=-1).item()
    
    predicted_label = labels[predicted_class_id]
    return predicted_label

# Funci贸n para obtener una respuesta basada en la intenci贸n
def get_response(intent):
    for i in data['intents']:
        if i['tag'] == intent:
            return random.choice(i['responses'])

# Interfaz para interactuar con el modelo
if __name__ == "__main__":
    print("Chatbot est谩 listo para recibir preguntas. Escribe 'salir' para terminar.")

    while True:
        user_input = input("Escribe tu pregunta: ")
        if user_input.lower() == "salir":
            print("隆Hasta luego!")
            break

        intent = predict_intent(user_input)
        print(f"Intento predicho: {intent}")
        response = get_response(intent)
        print(f"Respuesta del bot: {response}")
</code> 
        </pre>
        <!-- Interfaz con Streamlit -->
        <h2>Interfaz Gr谩fica con Streamlit</h2>
        <p>
            Se utiliz贸 <strong>Streamlit</strong> para construir una interfaz gr谩fica interactiva que permite a los usuarios interactuar con el chatbot de forma sencilla. 
            Streamlit proporciona una forma r谩pida de crear aplicaciones web directamente en Python sin necesidad de conocimientos en desarrollo web.
        </p>

        <ul>
            <li>La aplicaci贸n est谩 dise帽ada como un chat, donde el usuario puede escribir preguntas en un campo de texto.</li>
            <li>La conversaci贸n se muestra en tiempo real con una simulaci贸n de escritura del bot para hacer la interacci贸n m谩s natural.</li>
            <li>El historial de chat se mantiene hasta que el usuario decida reiniciar la conversaci贸n.</li>
        </ul>

        <!-- C贸digo de la interfaz con Streamlit -->
        <h2>C贸digo del Archivo: app_lightning.py</h2>
        <pre>
<code>
import streamlit as st
import time
from model_lightning import predict_intent, get_response

# Configuraci贸n de la p谩gina
st.set_page_config(page_title="UNACH BOT", page_icon="", layout="centered")

# Estilo personalizado con tema oscuro
st.markdown("""
    <style>
    .stApp {
        background-color: #1E1E1E;
        color: #FFFFFF;
    }
    .stTextInput > div > div > input {
        background-color: #2E2E2E;
        color: #FFFFFF;
    }
    .stButton > button {
        background-color: #4CAF50;
        color: #FFFFFF;
    }
    </style>
    """, unsafe_allow_html=True)

# T铆tulo y descripci贸n
st.title(' UNACH BOT Asistente Virtual')
st.markdown("Bienvenido al asistente virtual de la Universidad Nacional de Chimborazo. 驴En qu茅 puedo ayudarte hoy?")

# Inicializar la lista de mensajes si no existe
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "Hola, soy el asistente virtual de la UNACH. 驴En qu茅 puedo ayudarte?"}
    ]

# Funci贸n para a帽adir mensajes
def add_message(role, content):
    st.session_state.messages.append({"role": role, "content": content})

# Mostrar los mensajes
for message in st.session_state.messages[-50:]:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Entrada del usuario
user_input = st.chat_input("Escribe tu pregunta aqu铆...")

# Procesar la entrada del usuario
if user_input:
    add_message("user", user_input)

    # Mostrar "Escribiendo..." del chatbot
    with st.chat_message("assistant"):
        st.markdown("Escribiendo...")
        time.sleep(1.5)

    # Predecir la intenci贸n del mensaje del usuario y obtener la respuesta
    intent_prediction = predict_intent(user_input)
    response = get_response(intent_prediction)

    # A帽adir la respuesta del asistente
    add_message("assistant", response)
    st.rerun()

# Opci贸n para borrar el historial de chat
if st.button("Borrar historial de chat"):
    st.session_state.messages = [
        {"role": "assistant", "content": "Hola, soy el asistente virtual de la UNACH. 驴En qu茅 puedo ayudarte?"}
    ]
    st.rerun()

# Pie de p谩gina
st.markdown("---")
st.markdown("Desarrollado por Edwin Montenegro UNACH")
</code>
        </pre>
    </div>
    <div class="results-section">
        <h2>Resultados del Proyecto</h2>
        <p>En esta secci贸n se muestran algunos ejemplos de c贸mo el chatbot ha sido capaz de interactuar con los usuarios. A continuaci贸n se presentan im谩genes de diferentes escenarios donde el asistente ha respondido preguntas relacionadas con el proceso de titulaci贸n.</p>
        
        <!-- Ejemplo 1 -->
        <h3>Ejemplo 1: Pregunta sobre formas de titulaci贸n</h3>
        <div style="text-align:center;">
        <img src="imagenes\ejemplo1.png" alt="Ejemplo 1: Pregunta sobre formas de titulaci贸n" style="width:100%; max-width:800px;">
        </div>
        <p>En este ejemplo, el usuario pregunta sobre las formas de titulaci贸n disponibles. El chatbot responde con informaci贸n relevante acerca de las diversas opciones disponibles en la universidad.</p>
    
        <!-- Ejemplo 2 -->
        <h3>Ejemplo 2: Pregunta sobre c贸mo elegir un tema de tesis</h3>
        <div style="text-align:center;">
        <img src="imagenes\ejemplo4.png" alt="Ejemplo 2: Pregunta sobre c贸mo elegir un tema de tesis" style="width:100%; max-width:800px;">
        </div>
        <p>El usuario solicita informaci贸n sobre c贸mo seleccionar el tema de su tesis. El asistente virtual responde proporcionando los pasos necesarios para la elecci贸n del tema, asegurando que el estudiante reciba la gu铆a necesaria.</p>
    
        <!-- Ejemplo 3 -->
        <h3>Ejemplo 3: Solicitud de asesor para tesis</h3>
        <div style="text-align:center;">
        <img src="imagenes\ejemplo3.png" alt="Ejemplo 3: Solicitud de asesor para tesis" style="width:100%; max-width:800px;">
        </div>
        <p>En este caso, el asistente ayuda al usuario proporcion谩ndole informaci贸n sobre el proceso para solicitar un asesor de tesis en la universidad, gui谩ndolo en los pasos que debe seguir para completar este procedimiento.</p>
    
        <!-- Ejemplo 4 -->
        <h3>Ejemplo 4: Tiempo para completar el trabajo de titulaci贸n</h3>
        <div style="text-align:center;">
        <img src="imagenes\ejemplo5.png" alt="Ejemplo 4: Tiempo para completar el trabajo de titulaci贸n" style="width:100%; max-width:800px;">
        </div>
        <p>El chatbot responde a la pregunta del usuario sobre cu谩nto tiempo tiene para completar su trabajo de titulaci贸n, ofreciendo una explicaci贸n detallada sobre los plazos establecidos por la facultad.</p>
    
        <!-- Ejemplo 5 -->
        <h3>Ejemplo 5: Despedida del Chatbot</h3>
        <div style="text-align:center;">
        <img src="imagenes\despedida.png" alt="Ejemplo 5: Despedida del Chatbot" style="width:100%; max-width:800px;">
        </div>
        <p>Finalmente, el usuario agradece al asistente virtual por su ayuda, y el chatbot responde con un mensaje de despedida, indicando que siempre estar谩 disponible para ofrecer asistencia en el futuro.</p>
    </div>
    
    <!-- Conclusiones -->
    <div class="conclusions-section">
        <h2>Conclusiones Finales</h2>
        <p>
            El proyecto de chatbot de la UNACH ha sido un 茅xito al demostrar su capacidad para interactuar con los estudiantes y brindarles informaci贸n 煤til y precisa sobre el proceso de titulaci贸n. Utilizando t茅cnicas avanzadas de procesamiento de lenguaje natural (NLP) y el modelo RoBERTa, el asistente virtual puede identificar las intenciones del usuario y proporcionar respuestas relevantes.
        </p>
        <p>
            Las im谩genes anteriores muestran el buen desempe帽o del chatbot al responder preguntas relacionadas con los diferentes aspectos de la titulaci贸n. Adem谩s, el sistema ha sido entrenado utilizando t茅cnicas de aumento de datos para mejorar su capacidad de generalizaci贸n, permitiendo que el chatbot responda a una variedad de consultas de los estudiantes.
        </p>
        <p>
            En resumen, este chatbot representa un avance significativo en la automatizaci贸n del soporte a los estudiantes, y su implementaci贸n en la plataforma educativa permitir谩 mejorar la experiencia del usuario, facilitando el acceso a la informaci贸n y reduciendo la carga de trabajo del personal administrativo.
        </p>
    </div>
    <!-- Pie de p谩gina -->
    <footer>
        Desarrollado por el equipo de TI de la UNACH | 漏 2024
    </footer>

</body>
</html>
